?order
library(rvest)
url = 'http://rice.sinica.edu.tw/TRIM2/showTraits.php'
url=read_html(url)
url=html_nodes(url,"a")
nxturl=html_attr(url,"href")
url = 'http://rice.sinica.edu.tw/TRIM2/showTraits.php'
url=read_html(url)
url=html_nodes(url,"a")
title=html_text(url)
Phenotype <- cbind(title,nxturl)
View(Phenotype)
nxturl
sapply(nxturl,past0("http://rice.sinica.edu.tw/TRIM2/",))
sapply(nxturl,paste0("http://rice.sinica.edu.tw/TRIM2/",))
sapply(nxturl,function(x){
return(paste0("http://rice.sinica.edu.tw/TRIM2/",x))
})
nxturl <- sapply(nxturl,function(x){
return(paste0("http://rice.sinica.edu.tw/TRIM2/",x))
})
Phenotype <- cbind(title,nxturl)
View(Phenotype)
rownames(Phenotype) <- c(1:70)
View(Phenotype)
Phenotype <- Phenotype[c(67,70),]
View(Phenotype)
Phenotype <- cbind(title,nxturl)
rownames(Phenotype) <- c(1:70)
Phenotype <- Phenotype[-c(67,70),]
Phenotype <- cbind(title,nxturl)
rownames(Phenotype) <- c(1:70)
Phenotype <- Phenotype[-c(69,70),]
View(Phenotype)
Phenotype[1]
Phenotype[,1]
Phenotype[1,]
Phenotype[1]
Phenotype[,1]
Phenotype[,2]
Phenotype[1,2]
url=read_html(Phenotype[1,2])
url=html_nodes(url,"td")
mutant=html_text(url)
mutant[2]
Phenotype[2,2]
url=read_html(Phenotype[1,2])
url=html_nodes(url,"td")
mutant=html_text(url)
mutant[2]
Phenotype[3,2]
url=read_html(Phenotype[1,2])
url=html_nodes(url,"td")
mutant=html_text(url)
mutant[2]
Phenotype[4,2]
url=read_html(Phenotype[1,2])
url=html_nodes(url,"td")
mutant=html_text(url)
mutant[2]
mutant
Phenotype[4,2]
url=read_html(Phenotype[4,2])
url=html_nodes(url,"td")
mutant=html_text(url)
mutant[2]
mutant[1]
FindMutant <- function(x){
url=read_html(Phenotype[x,2])
url=html_nodes(url,"td")
mutant=html_text(url)
return(c(mutant[1],mutant[2]))
}
FindMutant(2)
write.csv(FindMutant(2),file="test.txt")
FindMutant(2)[1]
write.csv(FindMutant(2),file=FindMutant(2)[1]+".txt")
FindMutant(2)[1]
paste0(FindMutant(2)[1],".txt")
write.csv(FindMutant(2),file=paste0(FindMutant(2)[1],".txt"))
write.csv(FindMutant(2)[2],file=paste0(FindMutant(2)[1],".txt"))
Phenotype[2]
sapply(Phenotype[2], write)
write <- function(x){
write.csv(FindMutant(x)[2],file=paste0(FindMutant(x)[1],".txt"))
}
sapply(Phenotype[2], write)
Phenotype[2]
Phenotype[,2]
sapply(Phenotype[,2], write)
write(x)
write(2)
sapply(c(1:68), write)
c(1:68)
Phenotype[,2]
sapply(c(1:68), write)
sapply(c(1:68), FindMutant)
sapply(1, FindMutant)
sapply(2, FindMutant)
sapply(50, FindMutant)
sapply(40, FindMutant)
sapply(45, FindMutant)
paste0(FindMutant(2)[1],".txt")
sapply(46, FindMutant)
sapply(48, FindMutant)
sapply(49, FindMutant)
sapply(50, FindMutant)
sapply(c(1:10), write)
sapply(c(11:20), write)
sapply(c(21:30), write)
sapply(c(21:25), write)
sapply(c(21:22), write)
sapply(c(21), write)
sapply(c(22), write)
sapply(c(23), write)
sapply(c(24:30), write)
Phenotype[,2]
findMutant(Phenotype[1,2])
FindMutant(Phenotype[1,2])
Phenotype[1,2]
Phenotype[4,2]
View(Phenotype)
Phenotype[,1]
ct = 1
sapply(Phenotype[,1],function(x){
paste(ct,"_",x)
ct+=1
})
sapply(Phenotype[,1],function(x){
return((ct,"_",x))
ct = ct +1
})
Phenotype <- cbind(c(1:68),Phenotype)
View(Phenotype)
Phenotype[1,]
Phenotype[,1]
Phenotype[1,1]
FindMutant <- function(x){
url=read_html(Phenotype[x,3])
url=html_nodes(url,"td")
mutant=html_text(url)
return(c(mutant[1],mutant[2]))
}
FindMutant(1)
FindMutant(2)
write <- function(x){
write.csv(FindMutant(x)[2],file=paste0(Phenotype[x,1],FindMutant(x)[1],".txt"))
}
write(1)
write.csv(FindMutant(x)[2],file=paste0(Phenotype,"_",FindMutant(x)[1],".txt"))
write <- function(x){
write.csv(FindMutant(x)[2],file=paste0(Phenotype,"_",FindMutant(x)[1],".txt"))
}
write(1)
write <- function(x){
write.csv(FindMutant(x)[2],file=paste0(Phenotype[x,1],"_",FindMutant(x)[1],".txt"))
}
write(1)
sapply(c(1:68), write)
write(4)
write(5)
write(6)
sapply(c(7:15), write)
sapply(c(16:20), write)
sapply(c(21:25), write)
sapply(c(20:25), write)
sapply(c(22:25), write)
sapply(c(23:25), write)
sapply(c(26:35), write)
sapply(c(36:45), write)
sapply(c(42:45), write)
sapply(c(43:45), write)
sapply(c(46:55), write)
sapply(c(56:65), write)
sapply(c(66:68), write)
data <- as.factor(iris)
iris
data <- as.factor(iris3)
iris3
library(apriori)
install.packages(apriori)
install.packages("apriori")
#載入套件
library(neuralnet)
install.packages("neuralnet")
#載入套件
library(neuralnet)
#整理資料
data <- iris
data$setosa <- ifelse(data$Species == "setosa", 1, 0)
data$versicolor <- ifelse(data$Species == "versicolor", 1, 0)
data$virginica <- ifelse(data$Species == "virginica", 1, 0)
View(data)
#MultiLayer Perceptron Code
x <- as.matrix(seq(-10, 10, length = 100))
x
y <- logistic(x) + rnorm(100, sd = 0.2)
#訓練模型
f1 <- as.formula('setosa + versicolor + virginica  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width')
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,4),learningrate = 0.01)
#訓練模型
f1 <- as.formula('setosa + versicolor + virginica  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width')
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,4),learningrate = 0.01)
print(bpn)
#圖解BP
plot(bpn)
require(Metrics)
#MultiLayer Perceptron Code
x <- as.matrix(seq(-10, 10, length = 100))
y <- logistic(x) + rnorm(100, sd = 0.2)
#Loading the required packages
require(monmlp)
y <- logistic(x) + rnorm(100, sd = 0.2)
#Plotting Data
plot(x, y)
lines(x, logistic(x), lwd = 10, col = "gray")
#Fitting Model
mlpModel <- monmlp.fit(x = x, y = y, hidden1 = 3, monotone = 1,
n.ensemble = 15, bag = TRUE)
mlpModel <- monmlp.predict(x = x, weights = mlpModel)
#Plotting predicted value over actual values
for(i in 1:15){
lines(x, attr(mlpModel, "ensemble")[[i]], col = "red")
}
cat ("MSE for Gradient Descent Trained Model: ", mse(y, mlpModel))
cat ("MSE for Gradient Descent Trained Model: ", mse(y, mlpModel))
#Clear the workspace
rm(list = ls())
#Loading the required packages
require(monmlp)
require(Metrics)
#MultiLayer Perceptron Code
x <- as.matrix(seq(-10, 10, length = 100))
y <- logistic(x) + rnorm(100, sd = 0.2)
#Plotting Data
plot(x, y)
lines(x, logistic(x), lwd = 10, col = "gray")
#Fitting Model
mlpModel <- monmlp.fit(x = x, y = y, hidden1 = 3, monotone = 1,
n.ensemble = 15, bag = TRUE)
install.packages("kerasR")
iris
data <- iris
View(data)
dataset
datasets::airquality
#載入套件
library(neuralnet)
#整理資料
data <- iris
data$setosa <- ifelse(data$Species == "setosa", 1, 0)
data$versicolor <- ifelse(data$Species == "versicolor", 1, 0)
data$virginica <- ifelse(data$Species == "virginica", 1, 0)
#訓練模型
f1 <- as.formula('setosa + versicolor + virginica  ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width')
print(bpn)
bpn <- neuralnet(formula = f1, data = data, hidden = c(2,4),learningrate = 0.01)
#
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
#
source_url('https://gist.githubusercontent.com/Peque/41a9e20d6687f2f3108d/raw/85e14f3a292e126f1454864427e3a189c2fe33f3/nnet_plot_update.r')
#範例使用irisdata
data(iris)
#(2)分為訓練組和測試組資料集
set.seed(1117)
#取得總筆數
n <- nrow(iris)
#設定訓練樣本數70%
t_size = round(0.7 * n)
#取出樣本數的idx
t_idx <- sample(seq_len(n), size = t_size)
#訓練組樣本
traindata <- iris[t_idx,]
#測試組樣本
testdata <- iris[ - t_idx,]
#範例使用irisdata
data(iris)
#(2)分為訓練組和測試組資料集
set.seed(1117)
#取得總筆數
n <- nrow(iris)
#設定訓練樣本數70%
t_size = round(0.7 * n)
#取出樣本數的idx
t_idx <- sample(seq_len(n), size = t_size)
#訓練組樣本
traindata <- iris[t_idx,]
#測試組樣本
testdata <- iris[ - t_idx,]
nnetM <- nnet(formula = Species ~ ., linout = T, size = 3, decay = 0.001, maxit = 1000, trace = T, data = traindata)
nnetM <- nnet(formula = Species ~ ., linout = T, size = 3, decay = 0.001, maxit = 1000, trace = T, data = traindata)
install.packages("nnet")
library("nnet")
nnetM <- nnet(formula = Species ~ ., linout = T, size = 3, decay = 0.001, maxit = 1000, trace = T, data = traindata)
#(3)畫圖
plot.nnet(nnetM, wts.only = F)
#(4)預測
#test組執行預測
prediction <- predict(nnetM, testdata, type = 'class')
#預測結果
cm <- table(x = testdata$Species, y = prediction, dnn = c("實際", "預測"))
data <- iris
View(data)
library(devtools)
source_url('https://gist.githubusercontent.com/fawda123/7471137/raw/466c1474d0a505ff044412703516c34f1a4684a5/nnet_plot_update.r')
#(3)畫圖
plot.nnet(nnetM, wts.only = F)
#預測結果
cm <- table(x = testdata$Species, y = prediction, dnn = c("實際", "預測"))
cm
#取得總筆數
n <- nrow(iris)
#設定訓練樣本數70%
t_size = round(0.7 * n)
#取出樣本數的idx
t_idx <- sample(seq_len(n), size = t_size)
View(testdata)
View(traindata)
################################################################
#   Differential expression analysis with limma
library(Biobase)
install.packages("GEOquery")
################################################################
#   Differential expression analysis with limma
library(Biobase)
install.packages("GEOquery")
gset <- getGEO("GSE19983", GSEMatrix =TRUE, AnnotGPL=FALSE)
install.packages("Biobase")
library(rvest)
library(magrittr)
library(httr)
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822")
View(test)
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_text()
test
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_text %>% html_nodes(.,"h1")
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,"h1") %>% html_text()
test
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,".data") %>% html_text()
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,".data") %>% html_text()
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,".data") %>% html_text()
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,"h1") %>% html_text()
test <- read_html("http://ent.ltn.com.tw/news/breakingnews/2443822") %>% html_nodes(.,".date") %>% html_text()
print("hello")
source("https://bioconductor.org/biocLite.R")
biocLite("Rbowtie")
ibrary(swirl)
library(swirl)
source("https://wush978.github.io/R/init-swirl.R")
library(swirl)
library(swirl)
swirl()
x <- c(10.)
x <- c(10.4,5.6,3.1,6.4)
x
x
c(x,x)
c(1, 2, 3) - c(2, 4, 6)
print("XD")
source('~/.active-rstudio-document', echo=TRUE)
print("XD")
print("XD")
print("XD")
print("XD")
print("XD3")
print("XD3")
source('~/.active-rstudio-document', echo=TRUE)
print("XD2")
print("XD")
print("XD")
print("XD3")
print("XD1")
print("XD3")
source('~/.active-rstudio-document', echo=TRUE)
print("XD")
print("XD1")
print("XD2")
print("XD3")
print("XD2")
print("XD3")
library(dplyr)
library(magrittr)
library(NLP)
library(tidyr)
library(ggplot2)
# 丁守中 2017-12-17 - 2018-6-16
Di_report <- read.csv("Di_report.csv")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/FB_API_Crawler")
# 丁守中 2017-12-17 - 2018-6-16
Di_report <- read.csv("Di_report.csv")
# 姚文智　
Yao_report <- read.csv("Yao_report.csv")
# 柯文哲
Kao_report <- read.csv("Ko_report.csv")
# 建立 function 進行資料清理
DataClean <- function(DATA){
# please input data.frame and this function will output data.frame
# Cut time variable
DATA <- DATA %>% separate(time, c("date","time"), "T")
DATA <- DATA %>% separate(date, c("year","month","day"), "-")
# Drop 2017 data
DATA <- DATA[DATA$year == "2018", ]
# 轉換為數值資料
DATA$month <- DATA$month %>% as.numeric()
DATA$day <- DATA$day %>% as.numeric()
# Exchage month and day to halfmonth (以15天為間距)
halfmonth <- c()
for(i in DATA$day>15) {
if (i==TRUE) {
halfmonth <- c(halfmonth,0.5)
}else{
halfmonth <- c(halfmonth,0)
}
}
# 半月變數加上原始月份，指定回資料表
halfmonth <- DATA$month + halfmonth
halfmonth <- halfmonth %>% as.factor()
# 把半月變數資料放回去data frame
DATA <- cbind(DATA,halfmonth)
# 清除6月半資料
DATA <- DATA[DATA$halfmonth!=6.5,]
return(DATA)
}
Di_report <- DataClean(Di_report)
Yao_report <- DataClean(Yao_report)
Kao_report <- DataClean(Kao_report)
Di_report
Di_report$time
Di_report$year
summary(Di_report)
summary(Di_report$halfmonth)
## 畫圖 丁守中 柯文哲 姚文智 每半個月發文量
Di = summary(Di_report$halfmonth) %>% as.numeric()
yao = summary(Di_report$halfmonth) %>% as.numeric()
yao = summary(Yao_report$halfmonth) %>% as.numeric()
Ko = summary(Ko_report$halfmonth) %>% as.numeric()
Ko = summary(Kao_report$halfmonth) %>% as.numeric()
report_sum = data.frame(Di,yao,Ko)
report_sum = data.frame(c(Di,yao,Ko))
View(report_sum)
report_sum = data.frame()
rbind(Di,yao,Ko)
View(Kao_report)
## 畫圖 丁守中 柯文哲 姚文智 每半個月發文量
Di = summary(Di_report$halfmonth) %>% as.numeric()
Yao = summary(Yao_report$halfmonth) %>% as.numeric()
Ko = summary(Kao_report$halfmonth) %>% as.numeric()
rbind(Di,yao,Ko)
Ko
report_sum = rbind(Di,yao,Ko)
## 畫圖 丁守中 柯文哲 姚文智 每半個月發文量
Di = summary(Di_report$halfmonth) %>% as.numeric()
Yao = summary(Yao_report$halfmonth) %>% as.numeric()
Ko = summary(Kao_report$halfmonth) %>% as.numeric()
Di
Yao
Kao_report <- DataClean(Kao_report)
# 丁守中 2017-12-17 - 2018-6-16
Di_report <- read.csv("Di_report.csv")
# 姚文智　
Yao_report <- read.csv("Yao_report.csv")
# 柯文哲
Kao_report <- read.csv("Ko_report.csv")
# 建立 function 進行資料清理
DataClean <- function(DATA){
# please input data.frame and this function will output data.frame
# Cut time variable
DATA <- DATA %>% separate(time, c("date","time"), "T")
DATA <- DATA %>% separate(date, c("year","month","day"), "-")
# Drop 2017 data
DATA <- DATA[DATA$year == "2018", ]
# 轉換為數值資料
DATA$month <- DATA$month %>% as.numeric()
DATA$day <- DATA$day %>% as.numeric()
# Exchage month and day to halfmonth (以15天為間距)
halfmonth <- c()
for(i in DATA$day>15) {
if (i==TRUE) {
halfmonth <- c(halfmonth,0.5)
}else{
halfmonth <- c(halfmonth,0)
}
}
# 半月變數加上原始月份，指定回資料表
halfmonth <- DATA$month + halfmonth
halfmonth <- halfmonth %>% as.factor()
# 把半月變數資料放回去data frame
DATA <- cbind(DATA,halfmonth)
# 清除6月半資料
DATA <- DATA[DATA$halfmonth!=6.5,]
return(DATA)
}
Di_report <- DataClean(Di_report)
Yao_report <- DataClean(Yao_report)
Kao_report <- DataClean(Kao_report)
Di = summary(Di_report$halfmonth) %>% as.numeric()
Yao = summary(Yao_report$halfmonth) %>% as.numeric()
Ko = summary(Kao_report$halfmonth) %>% as.numeric()
Di
Di = summary(Di_report$halfmonth) %>% as.numeric()
Yao
Ko
report_sum = rbind(Di[1:11],yao[1:11],Ko)
report_sum = rbind(Di[1:11],Yao[1:11],Ko)
View(Yao_report)
View(report_sum)
row.names(report_sum) <- c("Di","Yao","Ko")
report_sum
colnames(report_sum) <- c("一月上","一月下","二月上","二月下","三月上","三月下","四月上","四月下","五月上","五月下","六月上")
report_sum <- report_sum %>% t()
report_sum
ggplot(report_sum)
