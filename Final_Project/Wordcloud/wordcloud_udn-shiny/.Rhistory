View(di)
# assign new id to 3 candi
new_id_var <- function(Data){
new <- rep(deparse(substitute(Data)),nrow(Data))
Data <- cbind(Data, new)
}
ko<-new_id_var(ko)
yao<-new_id_var(yao)
di<-new_id_var(di)
View(di)
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$content), ]
# sort data by candi and time
all <- all[with(all, order(new, year ,month, day)), ]
# re-assign new rowname
row.names(all) = c(1:nrow(all))
View(all)
# save the new data
write.table(all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ct-shiny/temp_ct.csv", sep = ",")
# save the new data
write.table(all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ct-shiny/CT_news_cleaning.csv", sep = ",")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/LTN")
di <- read.csv("C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/NewsCleaning/Di_ltn.csv")
setwd("C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/NewsCleaning")
library(magrittr)
# load data
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/LTN/Di")
data_1 <- read.csv("Di_JanLtnNews", encoding = "big5")
data_2 <- read.csv("Di_FebLtnNews", encoding = "big5")
data_3 <- read.csv("Di_MarLtnNews", encoding = "big5")
data_4 <- read.csv("Di_AprLtnNews", encoding = "big5")
data_5 <- read.csv("Di_MayLtnNews", encoding = "big5")
View(data_1)
# 重遺漏資訊
data_1 <- data_1 %>% na.omit()
data_2 <- data_2 %>% na.omit()
data_3 <- data_3 %>% na.omit()
data_4 <- data_4 %>% na.omit()
data_5 <- data_5 %>% na.omit()
# 移除重複性資料
data_1 <- data_1[!duplicated(data_1$bindtext), ]
data_2 <- data_2[!duplicated(data_2$bindtext), ]
data_3 <- data_3[!duplicated(data_3$bindtext), ]
data_4 <- data_4[!duplicated(data_4$bindtext), ]
data_5 <- data_5[!duplicated(data_5$bindtext), ]
Di_all <- rbind(data_1, data_2, data_3, data_4, data_5)
Di <- subset(Di_all, select = c(V1, bindtext))
Media <- c()
text <- c("LTN")
for( i in 1:length(Di$bindtext)){
Media <- rbind(Media, text)
}
Di <- cbind(Media, Di)
View(Di)
View(data_1)
View(data_1)
View(data_4)
# add time value
data_1 <- cbind(data_1, rep("1",nrow(data_1)))
# add time value
news_month <- rep("1",nrow(data_1))
data_1 <- cbind(data_1, news_month)
library(magrittr)
# load data
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/LTN/Di")
data_1 <- read.csv("Di_JanLtnNews", encoding = "big5")
data_2 <- read.csv("Di_FebLtnNews", encoding = "big5")
data_3 <- read.csv("Di_MarLtnNews", encoding = "big5")
data_4 <- read.csv("Di_AprLtnNews", encoding = "big5")
data_5 <- read.csv("Di_MayLtnNews", encoding = "big5")
# 清除格式有誤的資料
# data_1<- data_1[-4,]
# data_2<- data_2[-8,]
# data_3<- data_3[-34,]
# data_5<- data_5[-1,]
# data_5<- data_5[-57,]
# 重遺漏資訊
data_1 <- data_1 %>% na.omit()
data_2 <- data_2 %>% na.omit()
data_3 <- data_3 %>% na.omit()
data_4 <- data_4 %>% na.omit()
data_5 <- data_5 %>% na.omit()
# 移除重複性資料
data_1 <- data_1[!duplicated(data_1$bindtext), ]
data_2 <- data_2[!duplicated(data_2$bindtext), ]
data_3 <- data_3[!duplicated(data_3$bindtext), ]
data_4 <- data_4[!duplicated(data_4$bindtext), ]
data_5 <- data_5[!duplicated(data_5$bindtext), ]
# add time value
news_month <- rep("1",nrow(data_1))
data_1 <- cbind(data_1, news_month)
View(data_1)
news_month <- rep("2",nrow(data_2))
data_2 <- cbind(data_2, news_month)
news_month <- rep("3",nrow(data_3))
data_3 <- cbind(data_3, news_month)
news_month <- rep("4",nrow(data_4))
data_4 <- cbind(data_4, news_month)
news_month <- rep("5",nrow(data_5))
data_5 <- cbind(data_5, news_month)
View(data_5)
Di_all <- rbind(data_1, data_2, data_3, data_4, data_5)
View(Di_all)
Di <- subset(Di_all, select = c(V1, bindtext, news_month)
Di <- subset(Di_all, select = c(V1, bindtext, news_month))
View(Di)
Media <- c()
text <- c("LTN")
for( i in 1:length(Di$bindtext)){
Media <- rbind(Media, text)
}
Di <- cbind(Media, Di)
# assign new id to 3 candi
new_id_var <- function(Data){
new <- rep(deparse(substitute(Data)),nrow(Data))
Data <- cbind(Data, new)
}
Di<-new_id_var(Di)
# load data
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/LTN/Di")
# load data
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/LTN
")
# load data
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/LTN")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/LTN")
View(Di)
write.table(Di, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ltn-shiny/Di", sep = ",")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/LTN")
library(magrittr)
# load data
# 匯入資料組
data_1 <- read.csv("Ko_JanLtnNews", encoding = "big5")
data_2 <- read.csv("Ko_FebLtnNews", encoding = "big5")
data_3 <- read.csv("Ko_MarLtnNews", encoding = "big5")
data_4 <- read.csv("Ko_AprLtnNews", encoding = "big5")
data_5 <- read.csv("Ko_MayLtnNews", encoding = "big5")
library(magrittr)
# load data
# 匯入資料組
data_1 <- read.csv("Ko_JanLtnNews", encoding = "big5")
data_2 <- read.csv("Ko_FebLtnNews", encoding = "big5")
data_3 <- read.csv("Ko_MarLtnNews", encoding = "big5")
data_4 <- read.csv("Ko_AprLtnNews", encoding = "big5")
data_5 <- read.csv("Ko_MayLtnNews", encoding = "big5")
# 重遺漏資訊
data_1 <- data_1 %>% na.omit()
data_2 <- data_2 %>% na.omit()
data_3 <- data_3 %>% na.omit()
data_4 <- data_4 %>% na.omit()
data_5 <- data_5 %>% na.omit()
# 移除重複性資料
data_1 <- data_1[!duplicated(data_1$bindtext), ]
data_2 <- data_2[!duplicated(data_2$bindtext), ]
data_3 <- data_3[!duplicated(data_3$bindtext), ]
data_4 <- data_4[!duplicated(data_4$bindtext), ]
data_5 <- data_5[!duplicated(data_5$bindtext), ]
View(data_5)
# add time value
news_month <- rep("1",nrow(data_1))
data_1 <- cbind(data_1, news_month)
news_month <- rep("2",nrow(data_2))
data_2 <- cbind(data_2, news_month)
news_month <- rep("3",nrow(data_3))
data_3 <- cbind(data_3, news_month)
news_month <- rep("4",nrow(data_4))
data_4 <- cbind(data_4, news_month)
news_month <- rep("5",nrow(data_5))
data_5 <- cbind(data_5, news_month)
Ko_all <- rbind(data_1, data_2, data_3, data_4, data_5)
Ko <- subset(Ko_all, select = c(V1, bindtext, news_month))
Media <- c()
text <- c("LTN")
for( i in 1:length(Ko$bindtext)){
Media <- rbind(Media, text)
}
Ko <- cbind(Media, Ko)
View(Ko_all)
View(Ko)
# assign new id to 3 candi
new_id_var <- function(Data){
new <- rep(deparse(substitute(Data)),nrow(Data))
Data <- cbind(Data, new)
}
Ko<-new_id_var(Ko)
write.table(Ko, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ltn-shiny/Ko", sep = ",")
library(magrittr)
# load data
# 匯入資料組
data_1 <- read.csv("Yao_JanLtnNews", encoding = "big5")
data_2 <- read.csv("Yao_FebLtnNews", encoding = "big5")
data_3 <- read.csv("Yao_MarLtnNews", encoding = "big5")
data_4 <- read.csv("Yao_AprLtnNews", encoding = "big5")
data_5 <- read.csv("Yao_MayLtnNews", encoding = "big5")
# 清除格式有誤的資料
# data_1<- data_1[-4,]
# data_2<- data_2[-8,]
# data_3<- data_3[-34,]
# data_5<- data_5[-1,]
# data_5<- data_5[-57,]
# 重遺漏資訊
data_1 <- data_1 %>% na.omit()
data_2 <- data_2 %>% na.omit()
data_3 <- data_3 %>% na.omit()
data_4 <- data_4 %>% na.omit()
data_5 <- data_5 %>% na.omit()
# 移除重複性資料
data_1 <- data_1[!duplicated(data_1$bindtext), ]
data_2 <- data_2[!duplicated(data_2$bindtext), ]
data_3 <- data_3[!duplicated(data_3$bindtext), ]
data_4 <- data_4[!duplicated(data_4$bindtext), ]
data_5 <- data_5[!duplicated(data_5$bindtext), ]
# add time value
news_month <- rep("1",nrow(data_1))
data_1 <- cbind(data_1, news_month)
news_month <- rep("2",nrow(data_2))
data_2 <- cbind(data_2, news_month)
news_month <- rep("3",nrow(data_3))
data_3 <- cbind(data_3, news_month)
news_month <- rep("4",nrow(data_4))
data_4 <- cbind(data_4, news_month)
news_month <- rep("5",nrow(data_5))
data_5 <- cbind(data_5, news_month)
Yao_all <- rbind(data_1, data_2, data_3, data_4, data_5)
Yao <- subset(Yao_all, select = c(V1, bindtext, news_month))
Media <- c()
text <- c("LTN")
for( i in 1:length(Yao$bindtext)){
Media <- rbind(Media, text)
}
Yao <- cbind(Media, Yao)
# assign new id to 3 candi
new_id_var <- function(Data){
new <- rep(deparse(substitute(Data)),nrow(Data))
Data <- cbind(Data, new)
}
Yao<-new_id_var(Yao)
View(Yao)
write.table(Yao, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ltn-shiny/Yao", sep = ",")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ltn-shiny")
# load data
di <- read.csv("Di")
View(di)
ko <- read.csv("Ko")
yao <- read.csv("Yao")
View(ko)
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$content), ]
library(magrittr)
# load data
di <- read.csv("Di")
ko <- read.csv("Ko")
yao <- read.csv("Yao")
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
View(all)
# remove duplicated data
all <- all[!duplicated(all$bindtext), ]
# sort data by candi and time
all <- all[with(all, order(new, month)), ]
# sort data by candi and time
all <- all[with(all, order(new, news_month)), ]
# re-assign new rowname
row.names(all) = c(1:nrow(all))
# save the new data
write.table(all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_ltn-shiny/ltn_news_cleaning", sep = ",")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/UDN")
library(magrittr)
library(tidyr)
# ---- 資料清理 --------------------------------------------------------------
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/UDN/爬完的結果!!")
Di_data <- read.csv("Di_JanFebNews.csv", encoding = "big5")
Di_data2 <- read.csv("Di_MarAprNews.csv", encoding = "big5")
Di_data3 <- read.csv("Di_MayNews.csv", encoding = "big5")
# bind all
Di_all <- rbind(Di_data[,2:4], Di_data2[,2:4], Di_data3[,2:4])
# 清除NA
Di_all <- Di_all %>% na.omit()
#切開時間
Di_all <- Di_all %>% separate(V1, c("year","month","day"),"-")
Di_all <- Di_all %>% separate(day, c("date","time"), " ")
Di_all <- Di_all[with(Di_all, order(year ,month, date)), ]
Di_all <- Di_all[!duplicated(Di_all$V3), ]
Di_all<- Di_all[Di_all$year == "2018",]
row.names(Di_all) = c(1:687) # 由資料數重新編排號碼
View(Di_all)
# assign new id to 3 candi
new <- rep("Di",nrow(Di_all))
Di_all <- cbind(Di_all, new)
# save the new data
write.table(Di_all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny/Di.csv", sep = ",")
# ---- 資料清理 --------------------------------------------------------------
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/UDN/爬完的結果!!")
Yao_data <- read.csv("Yao_JanFebNews.csv")
Yao_data2 <- read.csv("Yao_MarAprNews.csv")
Yao_data3 <- read.csv("Yao_MayNews.csv")
# bind all
Yao_all <- rbind(Yao_data3[1:336, 1:4], Yao_data2[17:260,1:4], Yao_data[1:90, 1:4])
# 清除NA
Yao_all <- Yao_all %>% na.omit()
View(Yao_all)
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/UDN/爬完的結果!!")
Yao_data <- read.csv("Yao_JanFebNews.csv")
Yao_data2 <- read.csv("Yao_MarAprNews.csv")
Yao_data3 <- read.csv("Yao_MayNews.csv")
# bind all
Di_all <- rbind(Yao_data3[1:336, 1:4], Yao_data2[17:260,1:4], Yao_data[1:90, 1:4])
# 清除NA
Di_all <- Di_all %>% na.omit()
#切開時間
Di_all <- Di_all %>% separate(V1, c("year","month","day"),"-")
Di_all <- Di_all %>% separate(day, c("date","time"), " ")
Di_all <- Di_all[with(Di_all, order(year ,month, date)), ]
Di_all <- Di_all[!duplicated(Di_all$V3), ]
Di_all<- Di_all[Di_all$year == "2018",]
row.names(Di_all) = c(1:650) # 由資料數重新編排號碼
View(Di_all)
# assign new id to 3 candi
new <- rep("Yao",nrow(Di_all))
Di_all <- cbind(Di_all, new)
# save the new data
write.table(Di_all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny/Yao.csv", sep = ",")
library(magrittr)
library(tidyr)
# ---- 資料清理 --------------------------------------------------------------
# 匯入資料組
setwd("/Users/Weber/Documents/GitHub/NTU-CSX-DataScience--Group5/Finalproject/UDN/爬完的結果!!")
Ko_data <- read.csv("ko_Output.csv", encoding = "big5")
Ko_data2 <- read.csv("ko_Output2.csv", encoding = "big5")
# bind all
ko_all <- rbind(Ko_data[,3:5], Ko_data2[,2:4])
# 清除NA
ko_all <- ko_all %>% na.omit()
#切開時間
ko_all <- ko_all %>% separate(V2, c("year","month","day"),"-")
ko_all <- ko_all %>% separate(day, c("date","time"), " ")
ko_all <- ko_all[with(ko_all, order(year, month, date)), ]
ko_all <- ko_all[!duplicated(ko_all$bindtext), ]
row.names(ko_all) = c(1:3112) # 由資料數重新編排號碼
Ko <- subset(ko_all, select = c(month, date, V1, bindtext))
Media <- c()
text <- c("UDN")
for( i in 1:length(Ko$bindtext)){
Media <- rbind(Media, text)
}
Ko <- cbind(Media, Ko)
View(Ko)
# assign new id to 3 candi
new <- rep("Ko",nrow(Ko))
Ko <- cbind(Ko, new)
# save the new data
write.table(Ko, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny/Ko.csv", sep = ",")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny")
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
View(di)
View(ko)
View(yao)
View(yao)
# bind all data
yao <- subset(yao, select = c(month, date, V2, V3, new))
ko <- subset(ko, select = c(month, date, V1, V2, new))
ko <- subset(ko, select = c(month, date, V1, bindtext, new))
di <- subset(di, select = c(month, date, V2, V3, new))
names(ko) <- c(month, date, V2, V3, new)# rename
names(ko) <- c('month', 'date', 'V2', 'V3', 'new')# rename
# bind all data together
all <- rbind(di, ko, yao)
View(all)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$content), ]
library(magrittr)
library(tidyr)
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
# bind all data
yao <- subset(yao, select = c(month, date, V2, V3, new))
ko <- subset(ko, select = c(month, date, V1, bindtext, new))
di <- subset(di, select = c(month, date, V2, V3, new))
names(ko) <- c('month', 'date', 'V2', 'V3', 'new')# rename
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$V3), ]
View(all)
# sort data by candi and time
all <- all[with(all, order(new, month, date)), ]
# re-assign new rowname
row.names(all) = c(1:nrow(all))
all[all$new == "di",]
all$new == "di"
View(all)
all$new == "Di"
all$new == "Ko"
length(all$new == "Ko")
nrow(all$new == "Ko")
nrow(all[all$new=="Ko",])
nrow(all[all$new=="yao",])
nrow(all[all$new=="Yao",])
View(yao)
View(di)
View(ko)
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/UDN")
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/News_Crawler/聯合")
y <- read.csv("Yao_JanFebNews.csv")
d <- read.csv("Di_JanFebNews.csv")
View(d)
View(d)
View(y)
y <- subset(y ,select = c(V2, V3))
d <- subset(d ,select = c(V2, V3))
n <- rbind(y,d)
n <- n[!duplicated(n$V3), ]
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny")
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
library(magrittr)
library(tidyr)
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
View(di)
View(ko)
View(yao)
# subset
yao <- subset(yao, select = c(month, date, V2, V3, new))
ko <- subset(ko, select = c(month, date, V1, bindtext, new))
di <- subset(di, select = c(month ,date, V2, V3, new))
# bind all data together
all <- rbind(di, ko, yao)
names(ko) <- c('month' ,'date', 'V2', 'V3', 'new')
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$content), ]
library(magrittr)
library(tidyr)
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
# subset
yao <- subset(yao, select = c(month, date, V2, V3, new))
ko <- subset(ko, select = c(month, date, V1, bindtext, new))
di <- subset(di, select = c(month ,date, V2, V3, new))
names(ko) <- c('month' ,'date', 'V2', 'V3', 'new')
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
all <- all[!duplicated(all$V2), ]
# sort data by candi and time
all <- all[with(all, order(new, year ,month, day)), ]
# sort data by candi and time
all <- all[with(all, order(new,month, date)), ]
# re-assign new rowname
row.names(all) = c(1:nrow(all))
View(all)
library(magrittr)
library(tidyr)
# load data
yao <- read.csv("Yao.csv")
ko <- read.csv("Ko.csv")
di <- read.csv("Di.csv")
# subset
yao <- subset(yao, select = c(month, date, V2, V3, new))
ko <- subset(ko, select = c(month, date, V1, bindtext, new))
di <- subset(di, select = c(month ,date, V2, V3, new))
names(ko) <- c('month' ,'date', 'V2', 'V3', 'new')
# bind all data together
all <- rbind(di, ko, yao)
# delete Na data
all <- all %>% na.omit()
# remove duplicated data
# all <- all[!duplicated(all$V2), ]
# sort data by candi and time
all <- all[with(all, order(new,month, date)), ]
# re-assign new rowname
row.names(all) = c(1:nrow(all))
# save the new data
write.table(all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_udn-shiny/Udn_news_cleaning.csv", sep = ",")
