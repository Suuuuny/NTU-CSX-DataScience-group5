library(RColorBrewer)
library(wordcloud)
library(memoise)
library(tibble)
library(data.table)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(magrittr)
library(RColorBrewer)
library(wordcloud)
# setwd()
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/all")
# == load dataset
df_apple = read.csv('Apple_news_cleaning.csv',sep = ',')
df_ct = read.csv('CT_news_cleaning.csv',sep = ',')
df_udn = read.csv('Udn_news_cleaning.csv',sep = ',')
df_ltn = read.csv('ltn_news_cleaning',sep = ',')
df_fb = read.csv('FaceBookAPI-Taipei_new_edit.csv',sep = ',')
# == merge dataset together
# I would like to create a new frame for all data,
# with the media, candi, month, title and content as columns contained
name = c('media', 'candi', 'month', 'title', 'content')
# apple
df_apl = subset(df_apple, select = c('Media','new','month','title','content'))
names(df_apl) <- name
# ct
df_ct = subset(df_ct, select = c('media','new','month','title','content'))
names(df_ct) <- name
# udn
media = rep('udn',nrow(df_udn))
df_udn = cbind(df_udn, media)
df_udn = subset(df_udn, select = c('media','new','month','V2','V3'))
names(df_udn) <- name
# ltn
df_ltn = subset(df_ltn, select = c('Media','new','news_month','V1','bindtext'))
names(df_ltn) <- name
# fb
fb = rep('fb', nrow(df_fb))
df_fb = cbind(df_fb, fb)
df_fb = subset(df_fb, select = c('fb','name','month','post'))
names(df_fb) <- c('media', 'candi', 'month',  'content')
sum(is.na(df_fb))
df_fb[duplicated(df_fb),]
# join all together
# one problem is that df_fb doesn't get a title column
# so we decide to drop all title var and then join
df_all = data.frame()
df_all = rbind(df_apl, df_ct, df_ltn, df_udn)
# see if there is any prob
str(df_all)
# unique(df_all$media)
# lower case
for(i in nrow(df_all)){
df_all$media =  df_all$media %>% tolower()
}
# clean the data
# if there any na-value
sum(is.na(df_all))
# dup-value
df_all[duplicated(df_all), ]
# save file
write.table(df_all, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/all/all_news.csv")
write.table(df_fb, file = "C:/Users/Weber/Documents/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/all/all_fb.csv")
news_data = read.csv("all_news.csv")
fb_data = read.csv("all_fb.csv")
news_data = read.csv("all_news.csv")
fb_data = read.csv("all_fb.csv")
View(news_data)
# load data
news_data = read.csv("all_news.csv",sep = "")
fb_data = read.csv("all_fb.csv",sep = "")
news_data = read.csv("all_news.csv", sep = "")
View(news_data)
news_data[(news_data$media == "ct")&(news_data$candi == "Ko")&(news)]
news_data[(news_data$media == "ct")&(news_data$candi == "Ko")&(news_data$month == 2),]
df_test = news_data[(news_data$media == "ct")&(news_data$candi == "Ko")&(news_data$month == 2),]
View(df_test)
test <- function(Media,Candi,Month) {
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
}
test <- function(Media,Candi,Month) {
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
return(news)
}
test('apple','Ko',2)
test <- function(Media,Candi,Month) {
news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
}
news = test('apple','Ko',2)
View(news)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(memoise)
library(tibble)
library(data.table)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(magrittr)
library(RColorBrewer)
library(wordcloud)
news_data = read.csv("all_news.csv", sep = "")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(Media,Candi,Month) {
# Careful not to let just any name slip in here;
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
myCorpus = Corpus(VectorSource(news$content))
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ",x))
})
clean_doc <- function(docs){
clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞","分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含","為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Internet Explorer 10","新聞送上來！快加入自由電子報APP、LINE好友  2018年6月13日‧星期三‧戊戌年四月卅 注目新聞 1 中國卡車罷工延燒 司機高喊「打倒共產黨」！ 2 新版身分證票選出爐 設計師魯少綸奪首獎！ 3 洋腸又來！夜店外帶18歲妹 網站取名「台女很容易」... 4 侯友宜妻1塊土地99個門牌 蘇貞昌：太荒唐 5 連俞涵超正弟媳曝光…根本巨乳林志玲,","以上版本的瀏覽器。 爆")
for(i in 1:length(clean_words)){
docs <- tm_map(docs,toSpace, clean_words[i])
}
return(docs)
}
myCorpus <- clean_doc(myCorpus)
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)
# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(myCorpus, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
# 清除單字
for(i in c(1:length(freqFrame$Var1))){
if((freqFrame$Var1[i] %>% as.character %>% nchar) == 1){
freqFrame[i,] <- NA
}
}
freqFrame <- na.omit(freqFrame)
return(freqFrame)
})
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",3)
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(Media,Candi,Month) {
# Careful not to let just any name slip in here;
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
myCorpus = Corpus(VectorSource(news$content))
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ",x))
})
clean_doc <- function(docs){
clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞","分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含","為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Internet Explorer 10","新聞送上來！快加入自由電子報APP、LINE好友  2018年6月13日‧星期三‧戊戌年四月卅 注目新聞 1 中國卡車罷工延燒 司機高喊「打倒共產黨」！ 2 新版身分證票選出爐 設計師魯少綸奪首獎！ 3 洋腸又來！夜店外帶18歲妹 網站取名「台女很容易」... 4 侯友宜妻1塊土地99個門牌 蘇貞昌：太荒唐 5 連俞涵超正弟媳曝光…根本巨乳林志玲,","以上版本的瀏覽器。 爆")
for(i in 1:length(clean_words)){
docs <- tm_map(docs,toSpace, clean_words[i])
}
return(docs)
}
myCorpus <- clean_doc(myCorpus)
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)
# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(myCorpus, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
# 清除單字
for(i in c(1:length(freqFrame$Var1))){
if((freqFrame$Var1[i] %>% as.character %>% nchar) == 1){
freqFrame[i,] <- NA
}
}
freqFrame <- na.omit(freqFrame)
write.table(freqFrame, paste(Media,"_",Candi,"_",Month,".csv"), sep = "")
})
getTermMatrix("apple","Ko",3)
getwd()
setwd("~/GitHub/NTU-CSX-DataScience-group5/Final_Project/Wordcloud/wordcloud_all_news-shiny")
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",1)
getTermMatrix("apple","Ko",2)
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",4)
getTermMatrix("apple","Ko",5)
getTermMatrix("apple","Di",1)
getTermMatrix("apple","Di",2)
getTermMatrix("apple","Di",3)
getTermMatrix("apple","Di",4)
getTermMatrix("apple","Di",5)
getTermMatrix("apple","Yao",1)
getTermMatrix("apple","Yao",2)
getTermMatrix("apple","Yao",3)
getTermMatrix("apple","Yao",4)
getTermMatrix("apple","Yao",5)
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Yao",1)
nrow(news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),])
nrow(news_data[(news_data$media == "apple")&(news_data$candi == Yao)&(news_data$month == 1),])
nrow(news_data[(news_data$media == "apple")&(news_data$candi == "Yao")&(news_data$month == 1),])
getTermMatrix("ct","Ko",1)
getTermMatrix("ct","Ko",1)# ltn
getTermMatrix("ct","Ko",1)
getTermMatrix("ct","Ko",2)
getTermMatrix("ct","Ko",3)
getTermMatrix("ct","Ko",4)
getTermMatrix("ct","Ko",5)
getTermMatrix("ct","Di",1)
getTermMatrix("ct","Di",2)
getTermMatrix("ct","Di",3)
getTermMatrix("ct","Di",4)
getTermMatrix("ct","Di",5)
getTermMatrix("ct","Yao",1)
getTermMatrix("ct","Yao",2)
getTermMatrix("ct","Yao",3)
getTermMatrix("ct","Yao",4)
getTermMatrix("ct","Yao",5)
getTermMatrix("ct","Yao",2)
nrow(ews_data[(news_data$media == "ct")&(news_data$candi == "Yao")&(news_data$month == 2),])
nrow(news_data[(news_data$media == "ct")&(news_data$candi == "Yao")&(news_data$month == 2),])
getTermMatrix("ltn","Ko",1)
getTermMatrix("ltn","Ko",2)
getTermMatrix("ltn","Ko",3)
getTermMatrix("ltn","Ko",4)
getTermMatrix("ltn","Ko",5)
getTermMatrix("ltn","Di",1)
getTermMatrix("ltn","Di",2)
getTermMatrix("ltn","Di",3)
getTermMatrix("ltn","Di",4)
getTermMatrix("ltn","Di",5)
getTermMatrix("ltn","Yao",1)
getTermMatrix("ltn","Yao",2)
getTermMatrix("ltn","Yao",3)
getTermMatrix("ltn","Yao",4)
getTermMatrix("ltn","Yao",5)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",2)
getTermMatrix("udn","Ko",3)
getTermMatrix("udn","Ko",4)
getTermMatrix("udn","Ko",5)
getTermMatrix("udn","Di",1)
getTermMatrix("udn","Di",2)
getTermMatrix("udn","Di",3)
getTermMatrix("udn","Di",4)
getTermMatrix("udn","Di",5)
getTermMatrix("udn","Yao",1)
getTermMatrix("udn","Yao",2)
getTermMatrix("udn","Yao",3)
getTermMatrix("udn","Yao",4)
getTermMatrix("udn","Yao",5)
shiny::runApp()
get_file <- function(Media,Candi,Month) {
target_file = read.csv(paste(Media,"_",Candi,"_",Month,".csv"),sep = "")
return(target_file)
}
runApp()
# apple
getTermMatrix("apple","Ko",1)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(memoise)
library(tibble)
library(data.table)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(magrittr)
library(RColorBrewer)
library(wordcloud)
news_data = read.csv("all_news.csv", sep = "")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(Media,Candi,Month) {
# Careful not to let just any name slip in here;
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
myCorpus = Corpus(VectorSource(news$content))
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ",x))
})
clean_doc <- function(docs){
clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞","分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含","為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Internet Explorer 10","新聞送上來！快加入自由電子報APP、LINE好友  2018年6月13日‧星期三‧戊戌年四月卅 注目新聞 1 中國卡車罷工延燒 司機高喊「打倒共產黨」！ 2 新版身分證票選出爐 設計師魯少綸奪首獎！ 3 洋腸又來！夜店外帶18歲妹 網站取名「台女很容易」... 4 侯友宜妻1塊土地99個門牌 蘇貞昌：太荒唐 5 連俞涵超正弟媳曝光…根本巨乳林志玲,","以上版本的瀏覽器。 爆")
for(i in 1:length(clean_words)){
docs <- tm_map(docs,toSpace, clean_words[i])
}
return(docs)
}
myCorpus <- clean_doc(myCorpus)
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)
# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(myCorpus, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
# 清除單字
for(i in c(1:length(freqFrame$Var1))){
if((freqFrame$Var1[i] %>% as.character %>% nchar) == 1){
freqFrame[i,] <- NA
}
}
freqFrame <- na.omit(freqFrame)
# write.table(freqFrame, paste(Media,"_",Candi,"_",Month,".csv"), sep = "")
})
# apple
getTermMatrix("apple","Ko",1)
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(Media,Candi,Month) {
# Careful not to let just any name slip in here;
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
myCorpus = Corpus(VectorSource(news$content))
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ",x))
})
clean_doc <- function(docs){
clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞","分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含","為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Internet Explorer 10","新聞送上來！快加入自由電子報APP、LINE好友  2018年6月13日‧星期三‧戊戌年四月卅 注目新聞 1 中國卡車罷工延燒 司機高喊「打倒共產黨」！ 2 新版身分證票選出爐 設計師魯少綸奪首獎！ 3 洋腸又來！夜店外帶18歲妹 網站取名「台女很容易」... 4 侯友宜妻1塊土地99個門牌 蘇貞昌：太荒唐 5 連俞涵超正弟媳曝光…根本巨乳林志玲,","以上版本的瀏覽器。 爆")
for(i in 1:length(clean_words)){
docs <- tm_map(docs,toSpace, clean_words[i])
}
return(docs)
}
myCorpus <- clean_doc(myCorpus)
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)
# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(myCorpus, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
# 清除單字
for(i in c(1:length(freqFrame$Var1))){
if((freqFrame$Var1[i] %>% as.character %>% nchar) == 1){
freqFrame[i,] <- NA
}
}
freqFrame <- na.omit(freqFrame)
return(freqFrame)
# write.table(freqFrame, paste(Media,"_",Candi,"_",Month,".csv"), sep = "")
})
# apple
getTermMatrix("apple","Ko",1)
library(NLP)
library(tm)
library(RColorBrewer)
library(wordcloud)
library(memoise)
library(tibble)
library(data.table)
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(magrittr)
library(RColorBrewer)
library(wordcloud)
news_data = read.csv("all_news.csv", sep = "")
# Using "memoise" to automatically cache the results
getTermMatrix <- memoise(function(Media,Candi,Month) {
# Careful not to let just any name slip in here;
news <- news_data[(news_data$media == Media)&(news_data$candi == Candi)&(news_data$month == Month),]
myCorpus = Corpus(VectorSource(news$content))
toSpace <- content_transformer(function(x,pattern){
return(gsub(pattern," ",x))
})
clean_doc <- function(docs){
clean_words <- c("[A-Za-z0-9]","、","《","『","』","【","】","／","，","。","！","「","（","」","）","\n","；",">","<","＜","＞","分享","記者","攝影","提及","表示","報導","我們","他們","的","也","都","就","與","但","是","在","和","及","為","或","且","有","含","為達最佳瀏覽效果，建議使用 Chrome、Firefox 或 Internet Explorer 10","新聞送上來！快加入自由電子報APP、LINE好友  2018年6月13日‧星期三‧戊戌年四月卅 注目新聞 1 中國卡車罷工延燒 司機高喊「打倒共產黨」！ 2 新版身分證票選出爐 設計師魯少綸奪首獎！ 3 洋腸又來！夜店外帶18歲妹 網站取名「台女很容易」... 4 侯友宜妻1塊土地99個門牌 蘇貞昌：太荒唐 5 連俞涵超正弟媳曝光…根本巨乳林志玲,","以上版本的瀏覽器。 爆")
for(i in 1:length(clean_words)){
docs <- tm_map(docs,toSpace, clean_words[i])
}
return(docs)
}
myCorpus <- clean_doc(myCorpus)
mixseg = worker()
segment <- c("柯文哲","姚文智","丁守中","台北市長","選舉","候選人","台灣","選票","柯市長","民進黨","國民黨","台北市民","市民")
new_user_word(mixseg,segment)
# 有詞頻之後就可以去畫文字雲
jieba_tokenizer=function(d){
unlist(segment(d[[1]],mixseg))
}
seg = lapply(myCorpus, jieba_tokenizer)
freqFrame = as.data.frame(table(unlist(seg)))
# 清除單字
for(i in c(1:length(freqFrame$Var1))){
if((freqFrame$Var1[i] %>% as.character %>% nchar) == 1){
freqFrame[i,] <- NA
}
}
freqFrame <- na.omit(freqFrame)
write.table(freqFrame, paste(Media,"_",Candi,"_",Month,".csv"), sep = ",", row.names = FALSE)
})
# apple
getTermMatrix("apple","Ko",1)
getTermMatrix("apple","Ko",2)
getTermMatrix("apple","Ko",3)
getTermMatrix("apple","Ko",4)
getTermMatrix("apple","Ko",5)
getTermMatrix("apple","Di",1)
getTermMatrix("apple","Di",2)
getTermMatrix("apple","Di",3)
getTermMatrix("apple","Di",4)
getTermMatrix("apple","Di",5)
getTermMatrix("apple","Yao",1)
getTermMatrix("apple","Yao",2)
getTermMatrix("apple","Yao",3)
getTermMatrix("apple","Yao",4)
getTermMatrix("apple","Yao",5)
# ct
getTermMatrix("ct","Ko",1)
getTermMatrix("ct","Ko",2)
getTermMatrix("ct","Ko",3)
getTermMatrix("ct","Ko",4)
getTermMatrix("ct","Ko",5)
getTermMatrix("ct","Di",1)
getTermMatrix("ct","Di",2)
getTermMatrix("ct","Di",3)
getTermMatrix("ct","Di",4)
getTermMatrix("ct","Di",5)
getTermMatrix("ct","Yao",1)
getTermMatrix("ct","Yao",2)
getTermMatrix("ct","Yao",3)
getTermMatrix("ct","Yao",4)
getTermMatrix("ct","Yao",5)
# ltn
getTermMatrix("ltn","Ko",1)
getTermMatrix("ltn","Ko",2)
getTermMatrix("ltn","Ko",3)
getTermMatrix("ltn","Ko",4)
getTermMatrix("ltn","Ko",5)
getTermMatrix("ltn","Di",1)
getTermMatrix("ltn","Di",2)
getTermMatrix("ltn","Di",3)
getTermMatrix("ltn","Di",4)
getTermMatrix("ltn","Di",5)
getTermMatrix("ltn","Yao",1)
getTermMatrix("ltn","Yao",2)
getTermMatrix("ltn","Yao",3)
getTermMatrix("ltn","Yao",4)
getTermMatrix("ltn","Yao",5)
# udn
getTermMatrix("udn","Ko",1)
getTermMatrix("udn","Ko",2)
getTermMatrix("udn","Ko",3)
getTermMatrix("udn","Ko",4)
getTermMatrix("udn","Ko",5)
getTermMatrix("udn","Di",1)
getTermMatrix("udn","Di",2)
getTermMatrix("udn","Di",3)
getTermMatrix("udn","Di",4)
getTermMatrix("udn","Di",5)
getTermMatrix("udn","Yao",1)
getTermMatrix("udn","Yao",2)
getTermMatrix("udn","Yao",3)
getTermMatrix("udn","Yao",4)
getTermMatrix("udn","Yao",5)
getTermMatrix("ct","Yao",2)
getTermMatrix("ct","Di",1)
runApp()
target_file = read.csv("ltn _ Di _ 1 .csv.csv"),sep = ",")
target_file = read.csv("ltn _ Di _ 1 .csv.csv",sep = ",")
target_file = read.csv("ltn _ Di _ 1 .csv.csv")
target_file = read.csv("ltn _ Di _ 1.csv.csv")
target_file = read.csv("ltn _ Di _ 1.csv", sep = ",")
target_file = read.csv("ct _ Ko _ 1 .csv")
View(target_file)
target_file = read.csv("ct _ Ko _ 1.csv")
target_file = read.csv("ct _ Ko _ 1 .csv")
runApp()
fluidPage(
# Application title
titlePanel("Word Cloud"),
sidebarLayout(
# Sidebar with a slider and selection inputs
sidebarPanel(
selectInput("wordcloud_news", "請選擇候媒體",
choices = list("蘋果"="apple", "中時"="ct", "自由"="ltn","聯合"="udn")),
selectInput("wordcloud_news_candi", "請選擇候選人",
choices = list("柯文哲"="Ko", "丁守中"="Di", "姚文智"="Yao")),
selectInput("wordcloud_news_month", "請選擇月份",
choices = list("一月"="1", "二月"="2", "三月"="3", "四月"="4","五月"="5")),
actionButton("update", "Change"),
hr(),
sliderInput("freq",
"Minimum Frequency:",
min = 1,  max = 50, value = 15),
sliderInput("max",
"Maximum Number of Words:",
min = 1,  max = 300,  value = 100)
),
# Show Word Cloud
mainPanel(
plotOutput("plot")
)
)
)
runApp()
runApp()
View(target_file)
